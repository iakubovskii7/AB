{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Алгоритм Томпсона на батчах (без контекста)\n",
    "\n",
    "1. На первом батче распределяем юзеров 50% на 50%.\n",
    "2. Вероятность конверсии каждого варианта распределена по Beta распределению с $\\alpha=1$,\n",
    "$\\beta=1$.\n",
    "3. В конце каждого батча пересчитываем вероятности превосходства по точной формуле,\n",
    "взятой отсюда https://www.johndcook.com//UTMDABTR-005-05.pdf\n",
    "4. Распределяем трафик в пропорции вероятностей превосходства для каждого варианта\n",
    "5. Останавливаем эксперимент при достижении определенной вероятности превосходства,\n",
    "но не раньше определенного дня, чтобы учесть календарные факторы\n",
    "\n",
    "Потенциальные проблемы:\n",
    "- слишком рано отдаем трафик победителю\n",
    "- из-за дисбаланса распределения трафика может быть больше успешных конверсий в этом варианте\n",
    "(можно попробовать применить нормализацию)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Реализуем алгоритм***\n",
    "\n",
    "0. **Инициализация** - *BatchThompson(n_arms)*. Аргумент на вход: число вариантов сплита.\n",
    "Здесь также инициализируются массивы для параметров Бета-распределений и вероятность превосходства = 0.5.\n",
    "\n",
    "1. **Метод сплита** - *split_data()*. Исходя из вероятности превосходства вычисляем сплит по вариантам.\n",
    "Возвращаем данные по конверсии на текущем батче для пересчета Бета-распределений.\n",
    "\n",
    "2. **Метод изменения параметров распределения** - *.update_beta_params(data)*. Аргументы на вход: numpy массив со значениями конверсии по\n",
    "каждому варианту. В случае неравномерного распределения по вариантам ставятся пропуски.\n",
    " - Проверяем, чтобы число столбцов совпадало с числом вариантов из инициализации.\n",
    " - Суммируем нули и единицы и обновляем параметры\n",
    "\n",
    "3. **Метод пересчета** - *update_prob_super()*. Аргументов нет, так как учитывает измененные параметры\n",
    "$\\alpha$ (накопленное число успешных конверсий) и\n",
    "$\\beta$ (накопленное число неудачных конверсий) для всех вариантов.\n",
    " - Считаем по точной формуле\n",
    " - Выдаем массив из вероятностей превосходства\n",
    "\n",
    "4. **Вероятность превосходства** - *prob_super_tuple()*. Аргументов нет, так как берем пересчитанные параметры.\n",
    "5. **Критерий остановки** (*stopping_criterion*) - условия цикла while. Либо вероятность превосходства выше заданной\n",
    "величины, либо закончились наблюдения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "from numpy import ndarray\n",
    "from tqdm.notebook import tqdm\n",
    "from src.ab import get_size_zratio\n",
    "from src.mab import calc_prob_between\n",
    "\n",
    "# Графики\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.mab import plot_mab_results\n",
    "from src.mab import BatchThompson\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from joblib import Parallel, delayed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Эксперименты на разных теоретических конверсиях и размерах батча (summation vs normalization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "p1_control = np.round(np.linspace(0.01, 0.5, 3), 3)\n",
    "mde_test_effect = np.round(np.linspace(0.01, 0.15, 3), 3)\n",
    "tuple_batch_size_share = np.round(np.linspace(0.001, 0.1, 1), 3)\n",
    "\n",
    "result_experiments_df = pd.DataFrame(index=pd.MultiIndex.from_product(\n",
    "                                     [p1_control, mde_test_effect, tuple_batch_size_share],\n",
    "                                     names=[\"p1\", \"mde\", \"batch_size_share\"]),\n",
    "                                     columns=['probability_superiority_steps',\n",
    "                                              'cumulative_observations_step_list',\n",
    "                                              'n_obs_per_every_arm'])\n",
    "plot_file = PdfPages(\"/home/igor/Appbooster/proba.ai/AB/Plot/Thompson/Experiment3/Thompson.pdf\")\n",
    "def thompson_results(index):\n",
    "    p_list = [index[0], index[0] * (1 + index[1])]\n",
    "    batch_size_share = index[2]\n",
    "    bts = BatchThompson(p_list_mu=p_list, batch_size_share_mu=batch_size_share)\n",
    "    probability_superiority_steps, observations_step_list = bts.start_experiment()\n",
    "    cumulative_observations_step_list = np.cumsum(observations_step_list, axis=0)\n",
    "    # plot_file.savefig(plot_mab_results(p_list, batch_size_share,\n",
    "    #                                    probability_superiority_steps, cumulative_observations_step_list));\n",
    "    # plt.close();\n",
    "    return (p_list, batch_size_share,\n",
    "            probability_superiority_steps,\n",
    "            cumulative_observations_step_list\n",
    "            )\n",
    "plot_file = PdfPages(\"/home/igor/Appbooster/proba.ai/AB/Plot/Thompson/Experiment3/Thompson.pdf\")\n",
    "results_all =  Parallel(n_jobs=-1)(\n",
    "                             delayed(thompson_results)(index)\n",
    "                             for index, row in result_experiments_df.iterrows()\n",
    "                             )\n",
    "# for index, row in  tqdm(result_experiments_df.iterrows()):\n",
    "#\n",
    "#     p_list = [index[0], index[0] * (1 + index[1])]\n",
    "#     batch_size_share = index[2]\n",
    "#     bts = BatchThompson(p_list_mu=p_list, batch_size_share_mu=batch_size_share)\n",
    "#     probability_superiority_steps, observations_step_list = bts.start_experiment()\n",
    "#     cumulative_observations_step_list = np.cumsum(observations_step_list, axis=0)\n",
    "#     result_experiments_df.loc[index, \"n_obs_per_every_arm\"] = bts.n_obs_every_arm\n",
    "#     result_experiments_df.loc[index, \"probability_superiority_steps\"] = probability_superiority_steps\n",
    "#     result_experiments_df.loc[index, \"cumulative_observations_step_list\"] = cumulative_observations_step_list\n",
    "#     plot_file.savefig(plot_mab_results(p_list, batch_size_share,\n",
    "#                                        probability_superiority_steps, cumulative_observations_step_list));\n",
    "#     plt.close();\n",
    "# plot_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f08159ca95c48808638dc7a27205689"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "for index, row in  tqdm(result_experiments_df.iterrows()):\n",
    "    result_experiments_df.loc[index, \"probability_superiority_steps\"] = results_all[i][2]\n",
    "    result_experiments_df.loc[index, \"cumulative_observations_step_list\"] = results_all[i][3]\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробуем реализовать метод, описанный в статье\n",
    "https://www.researchgate.net/publication/352117401_Parallelizing_Thompson_Sampling\n",
    "\n",
    "Авторы предлагают следующий алгоритм. Пусть $k_a$ - число раз выбора руки $a$,\n",
    "$l_a = 1$ - число раз выбора руки подряд.\n",
    "\n",
    "Для каждого батча $t = 1, 2, .. T$:\n",
    "\n",
    "- смотрим на вероятности бета распределений\n",
    "- выбираем руку с наибольшей вероятностью\n",
    "- присваиваем $k_a = k_a + 1$\n",
    "- ЕСЛИ $k_a < 2^{l_a}$, то кидаем ВЕСЬ трафик в эту руку\n",
    "- ИНАЧЕ: присваиваем $l_a = l_a + 1$ и распределяем трафик в ОБЕ руки ПОЛНОСТЬЮ (без долей)\n",
    "- обновляем параметры и по новой\n",
    "\n",
    "Утверждается, что он довольно хорошо работает и для динамических батчей - когда размер заранее нам неизвестен"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cc673968216406d9a23d21927a097ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.083 0.917]\n",
      " [0.013 0.987]\n",
      " [0.001 0.999]]\n",
      "[array([1897, 1897]), array([1897, 1897]), array([1897, 1897])]\n",
      "[1, 2]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "def all_equal(lst):\n",
    "    for arr in lst[1:]:\n",
    "        if not np.array_equal(lst[0], arr, equal_nan=True):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class BatchThompson1(BatchThompson):\n",
    "\n",
    "    def split_data_random(self, best_arms: np.array):\n",
    "        data_split = np.empty((self.batch_size, self.n_arms))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            if i in best_arms:\n",
    "                data_split[:, i] = np.random.binomial(n=1, p=self.p_list[i], size=self.batch_size)\n",
    "            else:\n",
    "                data_split[:, i] = np.nan\n",
    "        return data_split\n",
    "\n",
    "\n",
    "    def start_experiment(self):\n",
    "        cumulative_observations = np.repeat(0, self.n_arms)\n",
    "        probability_superiority_step_list: List[ndarray] = []  # how share of traffic changes across experiment\n",
    "        observations_step_list = []\n",
    "        k_list = [0] * self.n_arms\n",
    "        l_list = [0] * self.n_arms\n",
    "\n",
    "        for i in tqdm(range(0, np.uint16(1 / (self.batch_size_share / self.n_arms)))):\n",
    "\n",
    "            # Determine argmax arm\n",
    "            if all_equal(self.probability_superiority_tuple):\n",
    "                best_arm = np.random.choice(len(self.probability_superiority_tuple[:-1]),\n",
    "                                            size=len(self.probability_superiority_tuple[:-1]))[0]\n",
    "            else:\n",
    "                best_arm = np.argmax(self.probability_superiority_tuple)\n",
    "            k_list[best_arm] += 1\n",
    "            if k_list[best_arm] == 2 ** l_list[best_arm]:\n",
    "                l_list[best_arm] += 1\n",
    "                batch_data = self.split_data_random(best_arms=np.arange(self.n_arms))  # based on generate batch online\n",
    "            elif k_list[best_arm] < 2 ** l_list[best_arm]:\n",
    "                batch_data = self.split_data_random(best_arms=np.array(best_arm))\n",
    "\n",
    "            batch_non_zero_observations_step = batch_data.shape[0] - np.isnan(batch_data).sum(axis=0)\n",
    "            cumulative_observations += batch_non_zero_observations_step\n",
    "            observations_step_list.append(batch_non_zero_observations_step)\n",
    "            # Updating all\n",
    "            self.update_beta_params(batch_data, method=\"summation\")  # update beta distributions parameters\n",
    "            self.update_prob_super(method_calc=\"integrating\") # update probability superiority\n",
    "\n",
    "            # Append for resulting\n",
    "            probability_superiority_step_list.append(self.probability_superiority_tuple)\n",
    "\n",
    "            stopping_criterion = (np.max(self.probability_superiority_tuple) >= 0.99) | \\\n",
    "                                 (np.max(cumulative_observations) >  self.n_obs_every_arm)\n",
    "            if stopping_criterion:\n",
    "                break\n",
    "\n",
    "        return np.round(probability_superiority_step_list, 3), observations_step_list,\\\n",
    "               k_list, l_list\n",
    "bt1 = BatchThompson1(p_list=[0.4, 0.42], batch_size_share=0.0)\n",
    "probability_superiority_experiment, observations_step_list, k_list, l_list = bt1.start_experiment()\n",
    "print(probability_superiority_experiment)\n",
    "print(observations_step_list)\n",
    "print(k_list)\n",
    "print(l_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проблема такого подхода - отдаем не в пропорциях, а полностью в какой-то батч.\n",
    "Попробуем объединить алгоритмы: будем разделять трафик согласно пропорциям,\n",
    "но с учетом накопленных побед для каждой руки. Соответственно, если число побед руки будет равно какому-то\n",
    "числу, которое зависит от шага, то меняем сплит 50 на 50.\n",
    "Эксперимент проводим на стохастической конверсии:\n",
    "- конверсия распределена случайно (экспоненциальное распределение) с неким мат ожиданием\n",
    "- размер батча будет случайной величиной из нормального распределения с мат ожиданием и дисперсией"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BatchThompsonMixed:\n",
    "    def __init__(self, mu_p_list: List, mu_batch_size: int):\n",
    "\n",
    "\n",
    "\n",
    "    def split_data_random(self, best_arms: np.array, p_):\n",
    "        data_split = np.empty((self.batch_size, self.n_arms))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            if i in best_arms:\n",
    "                data_split[:, i] = np.random.binomial(n=1, p=self.p_list[i], size=self.batch_size)\n",
    "            else:\n",
    "                data_split[:, i] = np.nan\n",
    "        return data_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.03515063035170591"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.exponential(scale=0.02, size=1).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}