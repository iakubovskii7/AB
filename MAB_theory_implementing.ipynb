{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Алгоритм Томпсона на батчах (без контекста)\n",
    "\n",
    "1. На первом батче распределяем юзеров 50% на 50%.\n",
    "2. Вероятность конверсии каждого варианта распределена по Beta распределению с $\\alpha=1$,\n",
    "$\\beta=1$.\n",
    "3. В конце каждого батча пересчитываем вероятности превосходства по точной формуле,\n",
    "взятой отсюда https://www.johndcook.com//UTMDABTR-005-05.pdf\n",
    "4. Распределяем трафик в пропорции вероятностей превосходства для каждого варианта\n",
    "5. Останавливаем эксперимент при достижении определенной вероятности превосходства,\n",
    "но не раньше определенного дня, чтобы учесть календарные факторы\n",
    "\n",
    "Потенциальные проблемы:\n",
    "- слишком рано отдаем трафик победителю\n",
    "- из-за дисбаланса распределения трафика может быть больше успешных конверсий в этом варианте\n",
    "(можно попробовать применить нормализацию)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Реализуем алгоритм***\n",
    "\n",
    "0. **Инициализация** - *BatchThompson(n_arms)*. Аргумент на вход: число вариантов сплита.\n",
    "Здесь также инициализируются массивы для параметров Бета-распределений и вероятность превосходства = 0.5.\n",
    "\n",
    "1. **Метод сплита** - *split_data()*. Исходя из вероятности превосходства вычисляем сплит по вариантам.\n",
    "Возвращаем данные по конверсии на текущем батче для пересчета Бета-распределений.\n",
    "\n",
    "2. **Метод изменения параметров распределения** - *.update_beta_params(data)*. Аргументы на вход: numpy массив со значениями конверсии по\n",
    "каждому варианту. В случае неравномерного распределения по вариантам ставятся пропуски.\n",
    " - Проверяем, чтобы число столбцов совпадало с числом вариантов из инициализации.\n",
    " - Суммируем нули и единицы и обновляем параметры\n",
    "\n",
    "3. **Метод пересчета** - *update_prob_super()*. Аргументов нет, так как учитывает измененные параметры\n",
    "$\\alpha$ (накопленное число успешных конверсий) и\n",
    "$\\beta$ (накопленное число неудачных конверсий) для всех вариантов.\n",
    " - Считаем по точной формуле\n",
    " - Выдаем массив из вероятностей превосходства\n",
    "\n",
    "4. **Вероятность превосходства** - *prob_super_tuple()*. Аргументов нет, так как берем пересчитанные параметры.\n",
    "5. **Критерий остановки** (*stopping_criterion*) - условия цикла while. Либо вероятность превосходства выше заданной\n",
    "величины, либо закончились наблюдения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нужно наблюдений в каждую руку для выявления эффекта в классическом АБ-тесте: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2ee256d0eb14e5ea7ac040d30bb879a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наблюдений в каждую руку во время эксперимента: \n",
      " [[ 19  19]\n",
      " [ 25  51]\n",
      " [ 31  84]\n",
      " [ 35 119]\n",
      " [ 38 155]\n",
      " [ 43 189]\n",
      " [ 49 221]\n",
      " [ 59 249]\n",
      " [ 68 279]\n",
      " [ 71 314]\n",
      " [ 74 350]\n",
      " [ 78 384]\n",
      " [ 80 421]]\n",
      "Вероятности превосходства каждой руки во время эксперимента: \n",
      " [[0.167 0.833]\n",
      " [0.147 0.853]\n",
      " [0.093 0.907]\n",
      " [0.066 0.934]\n",
      " [0.118 0.882]\n",
      " [0.163 0.837]\n",
      " [0.271 0.729]\n",
      " [0.23  0.77 ]\n",
      " [0.076 0.924]\n",
      " [0.066 0.934]\n",
      " [0.115 0.885]\n",
      " [0.042 0.958]\n",
      " [0.037 0.963]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from scipy.stats import beta\n",
    "from tqdm.notebook import tqdm\n",
    "from AB_classic import get_size_zratio\n",
    "from MAB import calc_prob_between\n",
    "\n",
    "# Графики\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def create_directory_plot(folder: str, file_name: str):\n",
    "    directory_plots = 'Plot/Thompson/' + folder + \"/\"\n",
    "    try:\n",
    "        os.mkdir(directory_plots)\n",
    "    except:\n",
    "        pass\n",
    "    beta_distr_plot = PdfPages(directory_plots + file_name + \".pdf\")\n",
    "    return beta_distr_plot\n",
    "\n",
    "\n",
    "class BatchThompson:\n",
    "    def __init__(self, experiment_name:str, p_list: List[float], batch_size_share: np.float):\n",
    "        self.p_list = p_list\n",
    "        self.n_arms = len(p_list)\n",
    "        self.n_obs_every_arm = get_size_zratio(p_list[0], p_list[1], alpha=0.05, beta=0.2)\n",
    "        self.batch_size_share = batch_size_share\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        self.alphas = np.repeat(1.0, self.n_arms)\n",
    "        self.bethas = np.repeat(1.0, self.n_arms)\n",
    "        self.probability_superiority_tuple = (0.5, 0.5)\n",
    "\n",
    "       # Generating data\n",
    "        np.random.seed(np.uint16(np.random.random(size=1) * 100).item())\n",
    "        self.data = np.random.binomial(n=[1,1], p=self.p_list, size=(self.n_obs_every_arm, self.n_arms))\n",
    "\n",
    "        print(f\"Нужно наблюдений в каждую руку для выявления эффекта в классическом АБ-тесте: \"\n",
    "              f\"{self.n_obs_every_arm}\")\n",
    "\n",
    "\n",
    "    def split_data_historic(self, cumulative_observations: List, batch_split_obs: List):\n",
    "        \"\"\"\n",
    "        Split data in every batch iteration\n",
    "        :param cumulative_observations: list with cumulative observations for every arm\n",
    "        :param batch_split_obs: how many observation we must extract this iter\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        n_rows, n_cols = np.max(batch_split_obs), self.n_arms\n",
    "        data_split = np.empty((n_rows, n_cols))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            data_split[:batch_split_obs[i], i] = \\\n",
    "                self.data[cumulative_observations[i] : cumulative_observations[i] + batch_split_obs[i], i]\n",
    "        return data_split\n",
    "\n",
    "\n",
    "    def split_data_random(self, batch_split_obs: np.array):\n",
    "        \"\"\"\n",
    "\n",
    "        :param batch_split_obs: size for every arm\n",
    "        :param probs: probability for conversion rate\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data_split = np.empty((np.max(batch_split_obs), self.n_arms))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            data_split[:batch_split_obs[i], i] = np.random.binomial(n=1, p=self.p_list[i],\n",
    "                                                                    size=batch_split_obs[i])\n",
    "        return data_split\n",
    "\n",
    "\n",
    "    def update_beta_params(self, batch_data: np.array, method:str):\n",
    "        if method == \"summation\":\n",
    "            self._alphas += np.nansum(batch_data, axis=0)\n",
    "            self._bethas += np.sum(batch_data == 0, axis=0)\n",
    "        elif method == \"normalization\":\n",
    "            S_list =  np.nansum(batch_data, axis=0)  # number of successes in within batch\n",
    "            F_list = np.sum(batch_data == 0, axis=0)\n",
    "            M = batch_data.shape[0]\n",
    "            K = self._n_arms\n",
    "\n",
    "            adding_alphas = (M / K ) * (np.array(S_list) / (np.array(S_list) + np.array(F_list)))\n",
    "            adding_bethas = (M / K ) * (1 - np.array(S_list) / (np.array(S_list) + np.array(F_list)))\n",
    "\n",
    "            adding_alphas = np.nan_to_num(adding_alphas)\n",
    "            adding_bethas = np.nan_to_num(adding_bethas)\n",
    "\n",
    "            self._alphas += adding_alphas\n",
    "            self._bethas += adding_bethas\n",
    "        return self._alphas, self._bethas\n",
    "\n",
    "\n",
    "    def update_prob_super(self, method_calc) -> Tuple:\n",
    "        if method_calc == 'integrating':\n",
    "            prob_superiority =  calc_prob_between(self.alphas, self.bethas)\n",
    "            self.probability_superiority_tuple = (prob_superiority, 1 - prob_superiority)\n",
    "\n",
    "\n",
    "    # def create_plots(self, beta_distr_plot):\n",
    "    #     x = np.linspace(0, 1, 100)\n",
    "    #     rv1 = beta(self.alphas[0], self.bethas[0])\n",
    "    #     rv2 = beta(self.alphas[1], self.bethas[1])\n",
    "    #     fix, ax = plt.subplots()\n",
    "    #     ax.plot(x, rv1.pdf(x), label='control')\n",
    "    #     ax.plot(x, rv2.pdf(x), label='testing')\n",
    "    #     leg = ax.legend();\n",
    "    #     plt.title(f\"Вероятность превосходства в %: \"\n",
    "    #               f\"{np.round(tuple(map(lambda x: x * 100, self.prob_superiority_tuple)), 1)}\")\n",
    "    #     beta_distr_plot.savefig()\n",
    "    #     plt.close()\n",
    "\n",
    "\n",
    "    def start_experiment(self):\n",
    "        probability_superiority_step_list = []  # how share of traffic changes across experiment\n",
    "        observations_step_list = []  # how many observations is cumulated in every step\n",
    "\n",
    "        # Plots\n",
    "        # folder, file_name = self.experiment_name, str(self.p1) + \"_\" + str(self.p2)\n",
    "        cumulative_observations = np.repeat(0, self.n_arms)  # how many observations we extract every iter for every arm\n",
    "\n",
    "        for i in tqdm(range(0, np.uint16(1 / (self.batch_size_share / self.n_arms)))):\n",
    "            # Create batch for iteration\n",
    "            batch_size = self.batch_size_share * self.n_arms * self.n_obs_every_arm\n",
    "            batch_split_obs = np.round(np.array(batch_size) * self.probability_superiority_tuple).astype(np.uint16)  # get number of observations every arm\n",
    "            cumulative_observations += batch_split_obs\n",
    "            # batch_data = batchT.split_data_historic(cumulative_observations=cumulative_observations,\n",
    "            #                                         batch_split_obs=batch_split_obs) # based on earlier generated distr\n",
    "            batch_data = self.split_data_random(batch_split_obs)  # based on generate batch online\n",
    "\n",
    "            # Updating all\n",
    "            self.update_beta_params(batch_data)  # update beta distributions parameters\n",
    "            self.update_prob_super(method_calc=\"integrating\") # update probability superiority\n",
    "\n",
    "            # Append for resulting\n",
    "            probability_superiority_step_list.append(self.probability_superiority_tuple)\n",
    "            observations_step_list.append(batch_split_obs)\n",
    "\n",
    "            stopping_criterion = (np.max(self.probability_superiority_tuple) >= 0.99) | \\\n",
    "                                 (np.max(cumulative_observations) >  self.n_obs_every_arm)\n",
    "            if stopping_criterion:\n",
    "                break\n",
    "\n",
    "        return np.round(probability_superiority_step_list, 3), observations_step_list\n",
    "\n",
    "bts = BatchThompson(\"Experiment5\", p_list=[0.4, 0.5], batch_size_share=0.05)\n",
    "probability_superiority_steps, observations_step_list = bts.start_experiment()\n",
    "print(f\"Наблюдений в каждую руку во время эксперимента: \"\n",
    "      f\"\\n {np.cumsum(observations_step_list, axis=0)}\")\n",
    "\n",
    "print(f\"Вероятности превосходства каждой руки во время эксперимента: \"\n",
    "      f\"\\n {probability_superiority_steps}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 19,  19],\n       [ 26,  51],\n       [ 37,  78],\n       [ 50, 103],\n       [ 68, 123],\n       [ 77, 152],\n       [ 86, 181],\n       [ 89, 217],\n       [ 90, 255],\n       [ 91, 292],\n       [ 96, 326],\n       [ 99, 361],\n       [100, 398]], dtype=uint64)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}