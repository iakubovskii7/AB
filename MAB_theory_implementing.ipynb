{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Алгоритм Томпсона на батчах (без контекста)\n",
    "\n",
    "1. На первом батче распределяем юзеров 50% на 50%.\n",
    "2. Вероятность конверсии каждого варианта распределена по Beta распределению с $\\alpha=1$,\n",
    "$\\beta=1$.\n",
    "3. В конце каждого батча пересчитываем вероятности превосходства по точной формуле,\n",
    "взятой отсюда https://www.johndcook.com//UTMDABTR-005-05.pdf\n",
    "4. Распределяем трафик в пропорции вероятностей превосходства для каждого варианта\n",
    "5. Останавливаем эксперимент при достижении определенной вероятности превосходства,\n",
    "но не раньше определенного дня, чтобы учесть календарные факторы\n",
    "\n",
    "Потенциальные проблемы:\n",
    "- слишком рано отдаем трафик победителю\n",
    "- из-за дисбаланса распределения трафика может быть больше успешных конверсий в этом варианте\n",
    "(можно попробовать применить нормализацию)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Реализуем алгоритм***\n",
    "\n",
    "0. **Инициализация** - *BatchThompson(n_arms)*. Аргумент на вход: число вариантов сплита.\n",
    "Здесь также инициализируются массивы для параметров Бета-распределений и вероятность превосходства = 0.5.\n",
    "\n",
    "1. **Метод сплита** - *split_data()*. Исходя из вероятности превосходства вычисляем сплит по вариантам.\n",
    "Возвращаем данные по конверсии на текущем батче для пересчета Бета-распределений.\n",
    "\n",
    "2. **Метод изменения параметров распределения** - *.update_beta_params(data)*. Аргументы на вход: numpy массив со значениями конверсии по\n",
    "каждому варианту. В случае неравномерного распределения по вариантам ставятся пропуски.\n",
    " - Проверяем, чтобы число столбцов совпадало с числом вариантов из инициализации.\n",
    " - Суммируем нули и единицы и обновляем параметры\n",
    "\n",
    "3. **Метод пересчета** - *update_prob_super()*. Аргументов нет, так как учитывает измененные параметры\n",
    "$\\alpha$ (накопленное число успешных конверсий) и\n",
    "$\\beta$ (накопленное число неудачных конверсий) для всех вариантов.\n",
    " - Считаем по точной формуле\n",
    " - Выдаем массив из вероятностей превосходства\n",
    "\n",
    "4. **Вероятность превосходства** - *prob_super_tuple()*. Аргументов нет, так как берем пересчитанные параметры.\n",
    "5. **Критерий остановки** (*stopping_criterion*) - условия цикла while. Либо вероятность превосходства выше заданной\n",
    "величины, либо закончились наблюдения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "from numpy import ndarray\n",
    "from tqdm.notebook import tqdm\n",
    "from src.ab import get_size_zratio\n",
    "from src.mab import calc_prob_between\n",
    "\n",
    "# Графики\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.mab import plot_mab_results\n",
    "from src.mab import BatchThompson\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from joblib import Parallel, delayed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Эксперименты на разных теоретических конверсиях и размерах батча (summation vs normalization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "p1_control = np.round(np.linspace(0.01, 0.5, 3), 3)\n",
    "mde_test_effect = np.round(np.linspace(0.01, 0.15, 3), 3)\n",
    "tuple_batch_size_share = np.round(np.linspace(0.001, 0.1, 1), 3)\n",
    "\n",
    "result_experiments_df = pd.DataFrame(index=pd.MultiIndex.from_product(\n",
    "                                     [p1_control, mde_test_effect, tuple_batch_size_share],\n",
    "                                     names=[\"p1\", \"mde\", \"batch_size_share\"]),\n",
    "                                     columns=['probability_superiority_steps',\n",
    "                                              'cumulative_observations_step_list',\n",
    "                                              'n_obs_per_every_arm'])\n",
    "plot_file = PdfPages(\"/home/igor/Appbooster/proba.ai/AB/Plot/Thompson/Experiment3/Thompson.pdf\")\n",
    "def thompson_results(index):\n",
    "    p_list = [index[0], index[0] * (1 + index[1])]\n",
    "    batch_size_share = index[2]\n",
    "    bts = BatchThompson(p_list_mu=p_list, batch_size_share_mu=batch_size_share)\n",
    "    probability_superiority_steps, observations_step_list = bts.start_experiment()\n",
    "    cumulative_observations_step_list = np.cumsum(observations_step_list, axis=0)\n",
    "    # plot_file.savefig(plot_mab_results(p_list, batch_size_share,\n",
    "    #                                    probability_superiority_steps, cumulative_observations_step_list));\n",
    "    # plt.close();\n",
    "    return (p_list, batch_size_share,\n",
    "            probability_superiority_steps,\n",
    "            cumulative_observations_step_list\n",
    "            )\n",
    "plot_file = PdfPages(\"/home/igor/Appbooster/proba.ai/AB/Plot/Thompson/Experiment3/Thompson.pdf\")\n",
    "results_all =  Parallel(n_jobs=-1)(\n",
    "                             delayed(thompson_results)(index)\n",
    "                             for index, row in result_experiments_df.iterrows()\n",
    "                             )\n",
    "# for index, row in  tqdm(result_experiments_df.iterrows()):\n",
    "#\n",
    "#     p_list = [index[0], index[0] * (1 + index[1])]\n",
    "#     batch_size_share = index[2]\n",
    "#     bts = BatchThompson(p_list_mu=p_list, batch_size_share_mu=batch_size_share)\n",
    "#     probability_superiority_steps, observations_step_list = bts.start_experiment()\n",
    "#     cumulative_observations_step_list = np.cumsum(observations_step_list, axis=0)\n",
    "#     result_experiments_df.loc[index, \"n_obs_per_every_arm\"] = bts.n_obs_every_arm\n",
    "#     result_experiments_df.loc[index, \"probability_superiority_steps\"] = probability_superiority_steps\n",
    "#     result_experiments_df.loc[index, \"cumulative_observations_step_list\"] = cumulative_observations_step_list\n",
    "#     plot_file.savefig(plot_mab_results(p_list, batch_size_share,\n",
    "#                                        probability_superiority_steps, cumulative_observations_step_list));\n",
    "#     plt.close();\n",
    "# plot_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f08159ca95c48808638dc7a27205689"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "for index, row in  tqdm(result_experiments_df.iterrows()):\n",
    "    result_experiments_df.loc[index, \"probability_superiority_steps\"] = results_all[i][2]\n",
    "    result_experiments_df.loc[index, \"cumulative_observations_step_list\"] = results_all[i][3]\n",
    "    i += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 probability_superiority_steps  \\\np1    mde  batch_size_share                                                      \n0.010 0.01 0.001             [[0.5, 0.5], [0.5, 0.5], [0.356, 0.644], [0.77...   \n      0.08 0.001             [[0.528, 0.472], [0.662, 0.338], [0.84, 0.16],...   \n      0.15 0.001             [[0.332, 0.668], [0.347, 0.653], [0.348, 0.652...   \n0.255 0.01 0.001             [[0.295, 0.705], [0.513, 0.487], [0.416, 0.584...   \n      0.08 0.001             [[0.318, 0.682], [0.168, 0.832], [0.353, 0.647...   \n      0.15 0.001             [[0.5, 0.5], [0.5, 0.5], [0.806, 0.194], [0.95...   \n0.500 0.01 0.001             [[0.586, 0.414], [0.688, 0.312], [0.326, 0.674...   \n      0.08 0.001             [[0.5, 0.5], [0.5, 0.5], [0.369, 0.631], [0.32...   \n      0.15 0.001             [[0.295, 0.705], [0.229, 0.771], [0.184, 0.816...   \n\n                                             cumulative_observations_step_list  \\\np1    mde  batch_size_share                                                      \n0.010 0.01 0.001             [[18, 18], [26, 26], [52, 52], [72, 88], [103,...   \n      0.08 0.001             [[31, 31], [101, 93], [165, 125], [187, 129], ...   \n      0.15 0.001             [[5, 5], [12, 19], [14, 23], [19, 34], [23, 42...   \n0.255 0.01 0.001             [[1, 1], [1, 2], [2, 2], [3, 3], [3, 4], [4, 5...   \n      0.08 0.001             [[8, 8], [13, 19], [15, 29], [21, 41], [24, 54...   \n      0.15 0.001             [[2, 2], [4, 4], [5, 5], [8, 5], [12, 5], [17,...   \n0.500 0.01 0.001             [[40, 40], [73, 63], [98, 74], [111, 101], [13...   \n      0.08 0.001             [[3, 3], [5, 5], [7, 7], [7, 8], [9, 13], [10,...   \n      0.15 0.001             [[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6...   \n\n                            n_obs_per_every_arm  \np1    mde  batch_size_share                      \n0.010 0.01 0.001                            NaN  \n      0.08 0.001                            NaN  \n      0.15 0.001                            NaN  \n0.255 0.01 0.001                            NaN  \n      0.08 0.001                            NaN  \n      0.15 0.001                            NaN  \n0.500 0.01 0.001                            NaN  \n      0.08 0.001                            NaN  \n      0.15 0.001                            NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>probability_superiority_steps</th>\n      <th>cumulative_observations_step_list</th>\n      <th>n_obs_per_every_arm</th>\n    </tr>\n    <tr>\n      <th>p1</th>\n      <th>mde</th>\n      <th>batch_size_share</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">0.010</th>\n      <th>0.01</th>\n      <th>0.001</th>\n      <td>[[0.5, 0.5], [0.5, 0.5], [0.356, 0.644], [0.77...</td>\n      <td>[[18, 18], [26, 26], [52, 52], [72, 88], [103,...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.08</th>\n      <th>0.001</th>\n      <td>[[0.528, 0.472], [0.662, 0.338], [0.84, 0.16],...</td>\n      <td>[[31, 31], [101, 93], [165, 125], [187, 129], ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.15</th>\n      <th>0.001</th>\n      <td>[[0.332, 0.668], [0.347, 0.653], [0.348, 0.652...</td>\n      <td>[[5, 5], [12, 19], [14, 23], [19, 34], [23, 42...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">0.255</th>\n      <th>0.01</th>\n      <th>0.001</th>\n      <td>[[0.295, 0.705], [0.513, 0.487], [0.416, 0.584...</td>\n      <td>[[1, 1], [1, 2], [2, 2], [3, 3], [3, 4], [4, 5...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.08</th>\n      <th>0.001</th>\n      <td>[[0.318, 0.682], [0.168, 0.832], [0.353, 0.647...</td>\n      <td>[[8, 8], [13, 19], [15, 29], [21, 41], [24, 54...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.15</th>\n      <th>0.001</th>\n      <td>[[0.5, 0.5], [0.5, 0.5], [0.806, 0.194], [0.95...</td>\n      <td>[[2, 2], [4, 4], [5, 5], [8, 5], [12, 5], [17,...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">0.500</th>\n      <th>0.01</th>\n      <th>0.001</th>\n      <td>[[0.586, 0.414], [0.688, 0.312], [0.326, 0.674...</td>\n      <td>[[40, 40], [73, 63], [98, 74], [111, 101], [13...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.08</th>\n      <th>0.001</th>\n      <td>[[0.5, 0.5], [0.5, 0.5], [0.369, 0.631], [0.32...</td>\n      <td>[[3, 3], [5, 5], [7, 7], [7, 8], [9, 13], [10,...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.15</th>\n      <th>0.001</th>\n      <td>[[0.295, 0.705], [0.229, 0.771], [0.184, 0.816...</td>\n      <td>[[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_experiments_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "109"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_size_zratio(0.5, 0.5 * (1+0.15), alpha=0.05, beta=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[0.322, 0.678],\n        [0.295, 0.705],\n        [0.679, 0.321],\n        [0.836, 0.164],\n        [0.913, 0.087],\n        [0.748, 0.252],\n        [0.878, 0.122],\n        [0.955, 0.045],\n        [0.986, 0.014],\n        [0.994, 0.006],\n        [1.   , 0.   ],\n        [0.999, 0.001],\n        [1.   , 0.   ],\n        [1.   , 0.   ],\n        [1.   , 0.   ],\n        [1.   , 0.   ],\n        [1.   , 0.   ],\n        [1.   , 0.   ],\n        [1.   , 0.   ],\n        [0.999, 0.001],\n        [0.999, 0.001],\n        [0.999, 0.001],\n        [1.   , 0.   ],\n        [1.   , 0.   ],\n        [0.999, 0.001]]),\n [array([675, 675], dtype=uint16),\n  array([242, 511], dtype=uint16),\n  array([294, 704], dtype=uint16),\n  array([354, 167], dtype=uint16),\n  array([849, 166], dtype=uint16),\n  array([905,  86], dtype=uint16),\n  array([1314,  443], dtype=uint16),\n  array([827, 115], dtype=uint16),\n  array([1000,   47], dtype=uint16),\n  array([711,  10], dtype=uint16),\n  array([1095,    6], dtype=uint16),\n  array([915,   0], dtype=uint16),\n  array([1258,    0], dtype=uint16),\n  array([644,   0], dtype=uint16),\n  array([881,   0], dtype=uint16),\n  array([1096,    0], dtype=uint16),\n  array([664,   0], dtype=uint16),\n  array([1445,    0], dtype=uint16),\n  array([734,   0], dtype=uint16),\n  array([898,   0], dtype=uint16),\n  array([759,   0], dtype=uint16),\n  array([1091,    0], dtype=uint16),\n  array([592,   0], dtype=uint16),\n  array([507,   0], dtype=uint16),\n  array([1249,    0], dtype=uint16)])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bts = BatchThompson(p_list_mu=[0.01, 0.0101], batch_size_share_mu=0.05)\n",
    "bts.start_experiment()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробуем реализовать метод, описанный в статье\n",
    "https://www.researchgate.net/publication/352117401_Parallelizing_Thompson_Sampling\n",
    "\n",
    "Авторы предлагают следующий алгоритм. Пусть $k_a$ - число раз выбора руки $a$,\n",
    "$l_a = 1$ - число раз выбора руки подряд.\n",
    "\n",
    "Для каждого батча $t = 1, 2, .. T$:\n",
    "\n",
    "- смотрим на вероятности бета распределений\n",
    "- выбираем руку с наибольшей вероятностью\n",
    "- присваиваем $k_a = k_a + 1$\n",
    "- ЕСЛИ $k_a < 2^{l_a}$, то кидаем ВЕСЬ трафик в эту руку\n",
    "- ИНАЧЕ: присваиваем $l_a = l_a + 1$ и распределяем трафик в ОБЕ руки ПОЛНОСТЬЮ (без долей)\n",
    "- обновляем параметры и по новой\n",
    "\n",
    "Утверждается, что он довольно хорошо работает и для динамических батчей - когда размер заранее нам неизвестен"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cc673968216406d9a23d21927a097ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.083 0.917]\n",
      " [0.013 0.987]\n",
      " [0.001 0.999]]\n",
      "[array([1897, 1897]), array([1897, 1897]), array([1897, 1897])]\n",
      "[1, 2]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "def all_equal(lst):\n",
    "    for arr in lst[1:]:\n",
    "        if not np.array_equal(lst[0], arr, equal_nan=True):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class BatchThompson1(BatchThompson):\n",
    "\n",
    "    def split_data_random(self, best_arms: np.array):\n",
    "        data_split = np.empty((self.batch_size, self.n_arms))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            if i in best_arms:\n",
    "                data_split[:, i] = np.random.binomial(n=1, p=self.p_list[i], size=self.batch_size)\n",
    "            else:\n",
    "                data_split[:, i] = np.nan\n",
    "        return data_split\n",
    "\n",
    "\n",
    "    def start_experiment(self):\n",
    "        cumulative_observations = np.repeat(0, self.n_arms)\n",
    "        probability_superiority_step_list: List[ndarray] = []  # how share of traffic changes across experiment\n",
    "        observations_step_list = []\n",
    "        k_list = [0] * self.n_arms\n",
    "        l_list = [0] * self.n_arms\n",
    "\n",
    "        for i in tqdm(range(0, np.uint16(1 / (self.batch_size_share / self.n_arms)))):\n",
    "\n",
    "            # Determine argmax arm\n",
    "            if all_equal(self.probability_superiority_tuple):\n",
    "                best_arm = np.random.choice(len(self.probability_superiority_tuple[:-1]),\n",
    "                                            size=len(self.probability_superiority_tuple[:-1]))[0]\n",
    "            else:\n",
    "                best_arm = np.argmax(self.probability_superiority_tuple)\n",
    "            k_list[best_arm] += 1\n",
    "            if k_list[best_arm] == 2 ** l_list[best_arm]:\n",
    "                l_list[best_arm] += 1\n",
    "                batch_data = self.split_data_random(best_arms=np.arange(self.n_arms))  # based on generate batch online\n",
    "            elif k_list[best_arm] < 2 ** l_list[best_arm]:\n",
    "                batch_data = self.split_data_random(best_arms=np.array(best_arm))\n",
    "\n",
    "            batch_non_zero_observations_step = batch_data.shape[0] - np.isnan(batch_data).sum(axis=0)\n",
    "            cumulative_observations += batch_non_zero_observations_step\n",
    "            observations_step_list.append(batch_non_zero_observations_step)\n",
    "            # Updating all\n",
    "            self.update_beta_params(batch_data, method=\"summation\")  # update beta distributions parameters\n",
    "            self.update_prob_super(method_calc=\"integrating\") # update probability superiority\n",
    "\n",
    "            # Append for resulting\n",
    "            probability_superiority_step_list.append(self.probability_superiority_tuple)\n",
    "\n",
    "            stopping_criterion = (np.max(self.probability_superiority_tuple) >= 0.99) | \\\n",
    "                                 (np.max(cumulative_observations) >  self.n_obs_every_arm)\n",
    "            if stopping_criterion:\n",
    "                break\n",
    "\n",
    "        return np.round(probability_superiority_step_list, 3), observations_step_list,\\\n",
    "               k_list, l_list\n",
    "bt1 = BatchThompson1(p_list=[0.4, 0.42], batch_size_share=0.0)\n",
    "probability_superiority_experiment, observations_step_list, k_list, l_list = bt1.start_experiment()\n",
    "print(probability_superiority_experiment)\n",
    "print(observations_step_list)\n",
    "print(k_list)\n",
    "print(l_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проблема такого подхода - отдаем не в пропорциях, а полностью в какой-то батч.\n",
    "Попробуем объединить алгоритмы: будем разделять трафик согласно пропорциям,\n",
    "но с учетом накопленных побед для каждой руки. Соответственно, если число побед руки будет равно какому-то\n",
    "числу, которое зависит от шага, то меняем сплит 50 на 50.\n",
    "Эксперимент проводим на стохастической конверсии:\n",
    "- конверсия распределена случайно (экспоненциальное распределение) с неким мат ожиданием\n",
    "- размер батча будет случайной величиной из нормального распределения с мат ожиданием и дисперсией"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BatchThompsonMixed:\n",
    "    def __init__(self, mu_p_list: List, mu_batch_size: int):\n",
    "\n",
    "\n",
    "\n",
    "    def split_data_random(self, best_arms: np.array, p_):\n",
    "        data_split = np.empty((self.batch_size, self.n_arms))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            if i in best_arms:\n",
    "                data_split[:, i] = np.random.binomial(n=1, p=self.p_list[i], size=self.batch_size)\n",
    "            else:\n",
    "                data_split[:, i] = np.nan\n",
    "        return data_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.03515063035170591"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.exponential(scale=0.02, size=1).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}