{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Алгоритм Томпсона на батчах (без контекста)\n",
    "\n",
    "1. На первом батче распределяем юзеров 50% на 50%.\n",
    "2. Вероятность конверсии каждого варианта распределена по Beta распределению с $\\alpha=1$,\n",
    "$\\beta=1$.\n",
    "3. В конце каждого батча пересчитываем вероятности превосходства по точной формуле,\n",
    "взятой отсюда https://www.johndcook.com//UTMDABTR-005-05.pdf\n",
    "4. Распределяем трафик в пропорции вероятностей превосходства для каждого варианта\n",
    "5. Останавливаем эксперимент при достижении определенной вероятности превосходства,\n",
    "но не раньше определенного дня, чтобы учесть календарные факторы\n",
    "\n",
    "Потенциальные проблемы:\n",
    "- слишком рано отдаем трафик победителю\n",
    "- из-за дисбаланса распределения трафика может быть больше успешных конверсий в этом варианте\n",
    "(можно попробовать применить нормализацию)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Реализуем алгоритм***\n",
    "\n",
    "0. **Инициализация** - *BatchThompson(n_arms)*. Аргумент на вход: число вариантов сплита.\n",
    "Здесь также инициализируются массивы для параметров Бета-распределений и вероятность превосходства = 0.5.\n",
    "\n",
    "1. **Метод сплита** - *split_data()*. Исходя из вероятности превосходства вычисляем сплит по вариантам.\n",
    "Возвращаем данные по конверсии на текущем батче для пересчета Бета-распределений.\n",
    "\n",
    "2. **Метод изменения параметров распределения** - *.update_beta_params(data)*. Аргументы на вход: numpy массив со значениями конверсии по\n",
    "каждому варианту. В случае неравномерного распределения по вариантам ставятся пропуски.\n",
    " - Проверяем, чтобы число столбцов совпадало с числом вариантов из инициализации.\n",
    " - Суммируем нули и единицы и обновляем параметры\n",
    "\n",
    "3. **Метод пересчета** - *update_prob_super()*. Аргументов нет, так как учитывает измененные параметры\n",
    "$\\alpha$ (накопленное число успешных конверсий) и\n",
    "$\\beta$ (накопленное число неудачных конверсий) для всех вариантов.\n",
    " - Считаем по точной формуле\n",
    " - Выдаем массив из вероятностей превосходства\n",
    "\n",
    "4. **Вероятность превосходства** - *prob_super_tuple()*. Аргументов нет, так как берем пересчитанные параметры.\n",
    "5. **Критерий остановки** (*stopping_criterion*) - условия цикла while. Либо вероятность превосходства выше заданной\n",
    "величины, либо закончились наблюдения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumulative_observs: (0.33359627354967003, 0.66640372645033)\n",
      "cumulative_observs: (0.18663998641173124, 0.8133600135882688)\n",
      "cumulative_observs: (0.11449910297969268, 0.8855008970203073)\n",
      "cumulative_observs: (0.2719014655505553, 0.7280985344494447)\n",
      "cumulative_observs: (0.48584173765541466, 0.5141582623445853)\n",
      "cumulative_observs: (0.15808134819226896, 0.8419186518077311)\n",
      "cumulative_observs: (0.2854576049588871, 0.7145423950411129)\n",
      "cumulative_observs: (0.404841693060582, 0.595158306939418)\n",
      "cumulative_observs: (0.345537082602015, 0.654462917397985)\n",
      "cumulative_observs: (0.29647287614355555, 0.7035271238564444)\n",
      "cumulative_observs: (0.19347951555245885, 0.8065204844475411)\n",
      "cumulative_observs: (0.24695760494998548, 0.7530423950500145)\n",
      "cumulative_observs: (0.2802274394644222, 0.7197725605355778)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Функции для вычисления вероятности превосходства по точной формуле\n",
    "from math import lgamma\n",
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def h(a, b, c, d):\n",
    "    num = lgamma(a + c) + lgamma(b + d) + lgamma(a + b) + lgamma(c + d)\n",
    "    den = lgamma(a) + lgamma(b) + lgamma(c) + lgamma(d) + lgamma(a + b + c + d)\n",
    "    return np.exp(num - den)\n",
    "\n",
    "@jit\n",
    "def g0(a, b, c):\n",
    "    return np.exp(lgamma(a + b) + lgamma(a + c) - (lgamma(a + b + c) + lgamma(a)))\n",
    "\n",
    "@jit\n",
    "def hiter(a, b, c, d):\n",
    "    while d > 1:\n",
    "        d -= 1\n",
    "        yield h(a, b, c, d) / d\n",
    "\n",
    "def g(a, b, c, d):\n",
    "    return g0(a, b, c) + sum(hiter(a, b, c, d))\n",
    "\n",
    "def calc_prob_between(alphas, bethas):\n",
    "    return g(alphas[0], bethas[0], alphas[1], bethas[1])\n",
    "\n",
    "\n",
    "class BatchThompson:\n",
    "    def __init__(self, n_arms: np.uint8):\n",
    "        self._n_arms = n_arms\n",
    "        self._alphas = np.repeat(1.0, n_arms)\n",
    "        self._bethas = np.repeat(1.0, n_arms)\n",
    "        self._prob_superiority_tuple = (0.5, 0.5)\n",
    "\n",
    "    def split_data_historic(self, data_experiment: np.array, cumulative_observs: List, batch_split_obs: List):\n",
    "        \"\"\"\n",
    "        Split data in every batch iteration\n",
    "        :param data_experiment: historic data\n",
    "        :param cumulative_observs: list with cumulative observations for every arm\n",
    "        :param batch_split_obs: how many observation we must extract this iter\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        n_rows, n_cols = np.max(batch_split_obs), self._n_arms\n",
    "        data_split = np.empty((n_rows, n_cols))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(data_experiment.shape[1]):\n",
    "            data_split[:batch_split_obs[i], i] = \\\n",
    "                data_experiment[cumulative_observs[i] : cumulative_observs[i] + batch_split_obs[i], i]\n",
    "        return data_split\n",
    "\n",
    "\n",
    "\n",
    "    def split_data_random(self, **kwargs):\n",
    "        \"\"\"\n",
    "\n",
    "        :param kwargs: changeable params for generation samples\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ...\n",
    "\n",
    "\n",
    "    def update_beta_params(self, batch_data: np.array):\n",
    "        assert data.shape[1] == self._n_arms\n",
    "\n",
    "        self._alphas += np.nansum(batch_data, axis=0)\n",
    "        self._bethas += np.sum(batch_data == 0, axis=0)\n",
    "\n",
    "    def update_prob_super(self, method_calc) -> Tuple:\n",
    "        if method_calc == 'integrating':\n",
    "            prob_superiority =  calc_prob_between(self._alphas, self._bethas)\n",
    "            self._prob_superiority_tuple = (prob_superiority, 1 - prob_superiority)\n",
    "            return self._prob_superiority_tuple\n",
    "\n",
    "\n",
    "# Experiment params\n",
    "n_obs, n_arms = 1000, 2\n",
    "batch_size = 100\n",
    "probability_superiority =  0.5\n",
    "stopping_criterion = ( (probability_superiority <= 0.9) | (probability_superiority >= 0.1) )\n",
    "\n",
    "\n",
    "# Generating data\n",
    "data = np.empty(shape=(n_obs, n_arms))\n",
    "np.random.seed(1)\n",
    "data[:, 0] = np.random.binomial(n=1, p=0.3, size=n_obs)\n",
    "data[:, 1] = np.random.binomial(n=1, p=0.31, size=n_obs)\n",
    "\n",
    "batchT = BatchThompson(n_arms=2)\n",
    "probability_superiority = batchT.update_prob_super(method_calc=\"integrating\") # recalculate shares\n",
    "cumulative_observs = np.repeat(0, n_arms)  # how many observations we extract every iter for every arm\n",
    "while (np.max(probability_superiority) <= 0.95) & (np.max(cumulative_observs) <  n_obs - batch_size):\n",
    "    batch_split_obs = np.round(np.array(batch_size) * probability_superiority).astype(np.uint16)  # get number of observations every arm\n",
    "    batch_data = batchT.split_data_historic(data_experiment=data, cumulative_observs=cumulative_observs,\n",
    "                                            batch_split_obs=batch_split_obs)\n",
    "    batchT.update_beta_params(batch_data)  # update beta distributions\n",
    "    cumulative_observs += batch_split_obs  # cumulative sum of observations for every arm\n",
    "    probability_superiority = batchT.update_prob_super(method_calc=\"integrating\") # recalculate shares\n",
    "    print(f\"cumulative_observs: {probability_superiority}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from AB_classic import get_size_zratio\n",
    "get_size_zratio(0.3, 0.35, 0.05, 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "?get_size_zratio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "0.16666666666666663"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.35 - 0.3) / 0.3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}