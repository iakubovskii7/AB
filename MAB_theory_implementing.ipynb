{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Алгоритм Томпсона на батчах (без контекста)\n",
    "\n",
    "1. На первом батче распределяем юзеров 50% на 50%.\n",
    "2. Вероятность конверсии каждого варианта распределена по Beta распределению с $\\alpha=1$,\n",
    "$\\beta=1$.\n",
    "3. В конце каждого батча пересчитываем вероятности превосходства по точной формуле,\n",
    "взятой отсюда https://www.johndcook.com//UTMDABTR-005-05.pdf\n",
    "4. Распределяем трафик в пропорции вероятностей превосходства для каждого варианта\n",
    "5. Останавливаем эксперимент при достижении определенной вероятности превосходства,\n",
    "но не раньше определенного дня, чтобы учесть календарные факторы\n",
    "\n",
    "Потенциальные проблемы:\n",
    "- слишком рано отдаем трафик победителю\n",
    "- из-за дисбаланса распределения трафика может быть больше успешных конверсий в этом варианте\n",
    "(можно попробовать применить нормализацию)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Реализуем алгоритм***\n",
    "\n",
    "0. **Инициализация** - *BatchThompson(n_arms)*. Аргумент на вход: число вариантов сплита.\n",
    "Здесь также инициализируются массивы для параметров Бета-распределений и вероятность превосходства = 0.5.\n",
    "\n",
    "1. **Метод сплита** - *split_data()*. Исходя из вероятности превосходства вычисляем сплит по вариантам.\n",
    "Возвращаем данные по конверсии на текущем батче для пересчета Бета-распределений.\n",
    "\n",
    "2. **Метод изменения параметров распределения** - *.update_beta_params(data)*. Аргументы на вход: numpy массив со значениями конверсии по\n",
    "каждому варианту. В случае неравномерного распределения по вариантам ставятся пропуски.\n",
    " - Проверяем, чтобы число столбцов совпадало с числом вариантов из инициализации.\n",
    " - Суммируем нули и единицы и обновляем параметры\n",
    "\n",
    "3. **Метод пересчета** - *update_prob_super()*. Аргументов нет, так как учитывает измененные параметры\n",
    "$\\alpha$ (накопленное число успешных конверсий) и\n",
    "$\\beta$ (накопленное число неудачных конверсий) для всех вариантов.\n",
    " - Считаем по точной формуле\n",
    " - Выдаем массив из вероятностей превосходства\n",
    "\n",
    "4. **Вероятность превосходства** - *prob_super_tuple()*. Аргументов нет, так как берем пересчитанные параметры.\n",
    "5. **Критерий остановки** (*stopping_criterion*) - условия цикла while. Либо вероятность превосходства выше заданной\n",
    "величины, либо закончились наблюдения."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import ndarray\n",
    "from scipy.stats import beta\n",
    "from tqdm.notebook import tqdm\n",
    "from AB_classic import get_size_zratio\n",
    "from MAB import calc_prob_between\n",
    "\n",
    "# Графики\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e89aaa76eb6f4870a78ed8084fd3ee7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наблюдений в каждую руку во время эксперимента: \n",
      " [[ 19  19]\n",
      " [ 47  29]\n",
      " [ 72  42]\n",
      " [ 90  62]\n",
      " [110  80]\n",
      " [126 102]\n",
      " [140 126]\n",
      " [150 154]\n",
      " [159 183]\n",
      " [169 211]\n",
      " [176 242]\n",
      " [183 273]\n",
      " [195 299]\n",
      " [203 329]\n",
      " [213 357]\n",
      " [226 382]\n",
      " [243 403]]\n",
      "Вероятности превосходства каждой руки во время эксперимента: \n",
      " [[0.747 0.253]\n",
      " [0.666 0.334]\n",
      " [0.482 0.518]\n",
      " [0.525 0.475]\n",
      " [0.416 0.584]\n",
      " [0.365 0.635]\n",
      " [0.259 0.741]\n",
      " [0.229 0.771]\n",
      " [0.274 0.726]\n",
      " [0.178 0.822]\n",
      " [0.174 0.826]\n",
      " [0.326 0.674]\n",
      " [0.223 0.777]\n",
      " [0.267 0.733]\n",
      " [0.342 0.658]\n",
      " [0.446 0.554]\n",
      " [0.46  0.54 ]]\n"
     ]
    }
   ],
   "source": [
    "def create_directory_plot(folder: str, file_name: str):\n",
    "    directory_plots = 'Plot/Thompson/' + folder + \"/\"\n",
    "    try:\n",
    "        os.mkdir(directory_plots)\n",
    "    except:\n",
    "        pass\n",
    "    beta_distr_plot = PdfPages(directory_plots + file_name + \".pdf\")\n",
    "    return beta_distr_plot\n",
    "\n",
    "\n",
    "class BatchThompson:\n",
    "    def __init__(self, p_list: List[float], batch_size_share: np.float):\n",
    "        self.p_list = p_list\n",
    "        self.n_arms = len(p_list)\n",
    "        self.n_obs_every_arm = get_size_zratio(p_list[0], p_list[1], alpha=0.05, beta=0.2)\n",
    "        self.batch_size_share = batch_size_share\n",
    "        self.batch_size = np.uint16((self.batch_size_share * self.n_arms * self.n_obs_every_arm).item())\n",
    "\n",
    "\n",
    "        self.alphas = np.repeat(1.0, self.n_arms)\n",
    "        self.bethas = np.repeat(1.0, self.n_arms)\n",
    "        self.probability_superiority_tuple = (0.5, 0.5)\n",
    "\n",
    "       # Generating data\n",
    "        np.random.seed(np.uint16(np.random.random(size=1) * 100).item())\n",
    "        self.data = np.random.binomial(n=[1,1], p=self.p_list, size=(self.n_obs_every_arm, self.n_arms))\n",
    "\n",
    "        # print(f\"Нужно наблюдений в каждую руку для выявления эффекта в классическом АБ-тесте: \"\n",
    "        #       f\"{self.n_obs_every_arm}\")\n",
    "\n",
    "\n",
    "    def split_data_historic(self, cumulative_observations: List, batch_split_obs: List):\n",
    "        \"\"\"\n",
    "        Split data in every batch iteration\n",
    "        :param cumulative_observations: list with cumulative observations for every arm\n",
    "        :param batch_split_obs: how many observation we must extract this iter\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        n_rows, n_cols = np.max(batch_split_obs), self.n_arms\n",
    "        data_split = np.empty((n_rows, n_cols))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            data_split[:batch_split_obs[i], i] = \\\n",
    "                self.data[cumulative_observations[i] : cumulative_observations[i] + batch_split_obs[i], i]\n",
    "        return data_split\n",
    "\n",
    "\n",
    "    def split_data_random(self, batch_split_obs: np.array):\n",
    "        \"\"\"\n",
    "\n",
    "        :param batch_split_obs: size for every arm\n",
    "        :param probs: probability for conversion rate\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data_split = np.empty((np.max(batch_split_obs), self.n_arms))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            data_split[:batch_split_obs[i], i] = np.random.binomial(n=1, p=self.p_list[i],\n",
    "                                                                    size=batch_split_obs[i])\n",
    "        return data_split\n",
    "\n",
    "\n",
    "    def update_beta_params(self, batch_data: np.array, method:str):\n",
    "        if method == \"summation\":\n",
    "            self.alphas += np.nansum(batch_data, axis=0)\n",
    "            self.bethas += np.sum(batch_data == 0, axis=0)\n",
    "        elif method == \"normalization\":\n",
    "            S_list =  np.nansum(batch_data, axis=0)  # number of successes in within batch\n",
    "            F_list = np.sum(batch_data == 0, axis=0)\n",
    "            M = batch_data.shape[0]\n",
    "            K = self.n_arms\n",
    "\n",
    "            adding_alphas = (M / K ) * (np.array(S_list) / (np.array(S_list) + np.array(F_list)))\n",
    "            adding_bethas = (M / K ) * (1 - np.array(S_list) / (np.array(S_list) + np.array(F_list)))\n",
    "\n",
    "            adding_alphas = np.nan_to_num(adding_alphas)\n",
    "            adding_bethas = np.nan_to_num(adding_bethas)\n",
    "\n",
    "            self.alphas += adding_alphas\n",
    "            self.bethas += adding_bethas\n",
    "        return self.alphas, self.bethas\n",
    "\n",
    "\n",
    "    def update_prob_super(self, method_calc) -> Tuple:\n",
    "        if method_calc == 'integrating':\n",
    "            prob_superiority =  calc_prob_between(self.alphas, self.bethas)\n",
    "            self.probability_superiority_tuple = (prob_superiority, 1 - prob_superiority)\n",
    "\n",
    "\n",
    "    # def create_plots(self, beta_distr_plot):\n",
    "    #     x = np.linspace(0, 1, 100)\n",
    "    #     rv1 = beta(self.alphas[0], self.bethas[0])\n",
    "    #     rv2 = beta(self.alphas[1], self.bethas[1])\n",
    "    #     fix, ax = plt.subplots()\n",
    "    #     ax.plot(x, rv1.pdf(x), label='control')\n",
    "    #     ax.plot(x, rv2.pdf(x), label='testing')\n",
    "    #     leg = ax.legend();\n",
    "    #     plt.title(f\"Вероятность превосходства в %: \"\n",
    "    #               f\"{np.round(tuple(map(lambda x: x * 100, self.prob_superiority_tuple)), 1)}\")\n",
    "    #     beta_distr_plot.savefig()\n",
    "    #     plt.close()\n",
    "\n",
    "\n",
    "    def start_experiment(self):\n",
    "\n",
    "        probability_superiority_step_list: List[ndarray] = []  # how share of traffic changes across experiment\n",
    "        observations_step_list: List[ndarray] = []  # how many observations is cumulated in every step\n",
    "\n",
    "        # Plots\n",
    "        # folder, file_name = self.experiment_name, str(self.p1) + \"_\" + str(self.p2)\n",
    "        cumulative_observations = np.repeat(0, self.n_arms)  # how many observations we extract every iter for every arm\n",
    "\n",
    "        for i in tqdm(range(0, np.uint16(1 / (self.batch_size_share / self.n_arms)))):\n",
    "            batch_split_obs = np.round(np.array(self.batch_size) * self.probability_superiority_tuple).astype(np.uint16)  # get number of observations every arm\n",
    "            cumulative_observations += batch_split_obs\n",
    "            # batch_data = batchT.split_data_historic(cumulative_observations=cumulative_observations,\n",
    "            #                                         batch_split_obs=batch_split_obs) # based on earlier generated distr\n",
    "            batch_data = self.split_data_random(batch_split_obs)  # based on generate batch online\n",
    "\n",
    "            # Updating all\n",
    "            self.update_beta_params(batch_data, method=\"normalization\")  # update beta distributions parameters\n",
    "            self.update_prob_super(method_calc=\"integrating\") # update probability superiority\n",
    "\n",
    "            # Append for resulting\n",
    "            probability_superiority_step_list.append(self.probability_superiority_tuple)\n",
    "            observations_step_list.append(batch_split_obs)\n",
    "\n",
    "            stopping_criterion = (np.max(self.probability_superiority_tuple) >= 0.99) | \\\n",
    "                                 (np.max(cumulative_observations) >  self.n_obs_every_arm)\n",
    "            if stopping_criterion:\n",
    "                break\n",
    "\n",
    "        return np.round(probability_superiority_step_list, 3), observations_step_list\n",
    "\n",
    "bts = BatchThompson(p_list=[0.4, 0.5], batch_size_share=0.05)\n",
    "probability_superiority_steps, observations_step_list = bts.start_experiment()\n",
    "print(f\"Наблюдений в каждую руку во время эксперимента: \"\n",
    "      f\"\\n {np.cumsum(observations_step_list, axis=0)}\")\n",
    "\n",
    "print(f\"Вероятности превосходства каждой руки во время эксперимента: \"\n",
    "      f\"\\n {probability_superiority_steps}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Эксперименты на разных теоретических конверсиях и размерах батча (summation vs normalization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "p1_control = np.round(np.linspace(0.01, 0.5, 10), 3)\n",
    "mde_test_effect = np.round(np.linspace(0, 0.15, 3), 3)\n",
    "tuple_batch_size_share = np.round(np.linspace(0.001, 0.1, 10), 3)\n",
    "\n",
    "result_experiments_df = pd.DataFrame(index=pd.MultiIndex.from_product([p1_control, mde_test_effect, tuple_batch_size_share],\n",
    "                                                                      names=[\"p1\", \"mde\", \"batch_size_share\"]),\n",
    "                                     columns=['probability_superiority_steps', 'observations_step_list',\n",
    "                                              'n_obs_per_every_arm'])\n",
    "for index, row in  tqdm(result_experiments_df.iterrows()):\n",
    "    p_list = [index[0], index[0] * (1 + index[1])]\n",
    "    batch_size_share = index[2]\n",
    "    bts = BatchThompson(p_list=p_list, batch_size_share=batch_size_share)\n",
    "    probability_superiority_steps, observations_step_list = bts.start_experiment()\n",
    "    result_experiments_df.loc[index, \"n_obs_per_every_arm\"] = bts.n_obs_every_arm\n",
    "    result_experiments_df.loc[index, \"probability_superiority_steps\"] = probability_superiority_steps\n",
    "    result_experiments_df.loc[index, \"observations_step_list\"] = observations_step_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробуем реализовать метод, описанный в статье\n",
    "https://www.researchgate.net/publication/352117401_Parallelizing_Thompson_Sampling\n",
    "\n",
    "Авторы предлагают следующий алгоритм. Пусть $k_a$ - число раз выбора руки $a$,\n",
    "$l_a = 1$ - число раз выбора руки подряд.\n",
    "\n",
    "Для каждого батча $t = 1, 2, .. T$:\n",
    "\n",
    "- смотрим на вероятности бета распределений\n",
    "- выбираем руку с наибольшей вероятностью\n",
    "- присваиваем $k_a = k_a + 1$\n",
    "- ЕСЛИ $k_a < 2^{l_a}$, то кидаем ВЕСЬ трафик в эту руку\n",
    "- ИНАЧЕ: присваиваем $l_a = l_a + 1$ и распределяем трафик в ОБЕ руки ПОЛНОСТЬЮ (без долей)\n",
    "- обновляем параметры и по новой\n",
    "\n",
    "Утверждается, что он довольно хорошо работает и для динамических батчей - когда размер заранее нам неизвестен"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cc673968216406d9a23d21927a097ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.083 0.917]\n",
      " [0.013 0.987]\n",
      " [0.001 0.999]]\n",
      "[array([1897, 1897]), array([1897, 1897]), array([1897, 1897])]\n",
      "[1, 2]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "def all_equal(lst):\n",
    "    for arr in lst[1:]:\n",
    "        if not np.array_equal(lst[0], arr, equal_nan=True):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class BatchThompson1(BatchThompson):\n",
    "\n",
    "\n",
    "    def split_data_random(self, best_arms: np.array):\n",
    "        data_split = np.empty((self.batch_size, self.n_arms))\n",
    "        data_split[:] = np.nan\n",
    "        for i in range(self.n_arms):\n",
    "            if i in best_arms:\n",
    "                data_split[:, i] = np.random.binomial(n=1, p=self.p_list[i], size=self.batch_size)\n",
    "            else:\n",
    "                data_split[:, i] = np.nan\n",
    "        return data_split\n",
    "\n",
    "\n",
    "    def start_experiment(self):\n",
    "        cumulative_observations = np.repeat(0, self.n_arms)\n",
    "        probability_superiority_step_list: List[ndarray] = []  # how share of traffic changes across experiment\n",
    "        observations_step_list = []\n",
    "        k_list = [0] * self.n_arms\n",
    "        l_list = [0] * self.n_arms\n",
    "\n",
    "        for i in tqdm(range(0, np.uint16(1 / (self.batch_size_share / self.n_arms)))):\n",
    "\n",
    "            # Determine argmax arm\n",
    "            if all_equal(self.probability_superiority_tuple):\n",
    "                best_arm = np.random.choice(len(self.probability_superiority_tuple[:-1]),\n",
    "                                            size=len(self.probability_superiority_tuple[:-1]))[0]\n",
    "            else:\n",
    "                best_arm = np.argmax(self.probability_superiority_tuple)\n",
    "            k_list[best_arm] += 1\n",
    "            if k_list[best_arm] == 2 ** l_list[best_arm]:\n",
    "                l_list[best_arm] += 1\n",
    "                batch_data = self.split_data_random(best_arms=np.arange(self.n_arms))  # based on generate batch online\n",
    "            elif k_list[best_arm] < 2 ** l_list[best_arm]:\n",
    "                batch_data = self.split_data_random(best_arms=np.array(best_arm))\n",
    "\n",
    "            batch_non_zero_observations_step = batch_data.shape[0] - np.isnan(batch_data).sum(axis=0)\n",
    "            cumulative_observations += batch_non_zero_observations_step\n",
    "            observations_step_list.append(batch_non_zero_observations_step)\n",
    "            # Updating all\n",
    "            self.update_beta_params(batch_data, method=\"summation\")  # update beta distributions parameters\n",
    "            self.update_prob_super(method_calc=\"integrating\") # update probability superiority\n",
    "\n",
    "            # Append for resulting\n",
    "            probability_superiority_step_list.append(self.probability_superiority_tuple)\n",
    "\n",
    "            stopping_criterion = (np.max(self.probability_superiority_tuple) >= 0.99) | \\\n",
    "                                 (np.max(cumulative_observations) >  self.n_obs_every_arm)\n",
    "            if stopping_criterion:\n",
    "                break\n",
    "\n",
    "        return np.round(probability_superiority_step_list, 3), observations_step_list,\\\n",
    "               k_list, l_list\n",
    "bt1 = BatchThompson1(p_list=[0.4, 0.42], batch_size_share=0.1)\n",
    "probability_superiority_experiment, observations_step_list, k_list, l_list = bt1.start_experiment()\n",
    "print(probability_superiority_experiment)\n",
    "print(observations_step_list)\n",
    "print(k_list)\n",
    "print(l_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([61, 61]),\n array([61, 61]),\n array([61,  0]),\n array([61, 61]),\n array([61,  0]),\n array([61,  0]),\n array([61,  0]),\n array([61, 61]),\n array([61,  0])]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_step_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "9489"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt1.n_obs_every_arm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 189,  189],\n       [ 378,  378],\n       [ 567,  567],\n       [ 756,  756],\n       [ 756,  945],\n       [ 945, 1134],\n       [ 945, 1323],\n       [ 945, 1512],\n       [ 945, 1701],\n       [1134, 1890],\n       [1134, 2079],\n       [1134, 2268],\n       [1134, 2457],\n       [1134, 2646],\n       [1134, 2835],\n       [1134, 3024],\n       [1134, 3213],\n       [1323, 3402],\n       [1323, 3591],\n       [1323, 3780],\n       [1323, 3969],\n       [1323, 4158],\n       [1323, 4347],\n       [1323, 4536],\n       [1323, 4725],\n       [1323, 4914],\n       [1323, 5103],\n       [1323, 5292],\n       [1323, 5481],\n       [1323, 5670],\n       [1323, 5859],\n       [1323, 6048],\n       [1323, 6237],\n       [1512, 6426],\n       [1512, 6615],\n       [1512, 6804],\n       [1512, 6993],\n       [1512, 7182],\n       [1512, 7371],\n       [1512, 7560],\n       [1512, 7749],\n       [1512, 7938],\n       [1512, 8127],\n       [1512, 8316],\n       [1512, 8505],\n       [1512, 8694],\n       [1512, 8883],\n       [1512, 9072],\n       [1512, 9261],\n       [1512, 9450],\n       [1512, 9639]])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(observations_step_list, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}